{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVPA NHP pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this pipeline perfroms decoding analysis on pseudotrials sampled from monkey A recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import numpy as np\n",
    "from scipy.io import loadmat \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "from joblib import Parallel, delayed\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data folders. subdirectories & subject indices \n",
    "datadir = ''\n",
    "fn = 'monkey_a_mvpa_pseudotrials.mat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def partition_datasets(features,labels):\n",
    "    \"\"\"generates vector with targets\n",
    "       note: task A/1 : colour relevant. task B/2: motion relevant\n",
    "    \"\"\"\n",
    "    datasets = {}\n",
    "    # train task A relevant dim (colour):\n",
    "    datasets['taskA_reldim'] = {}    \n",
    "    X = features[labels[:,0]==1]\n",
    "    targets = labels[labels[:,0]==1,2]    \n",
    "    targets = targets>3 # low vs high value for col\n",
    "    \n",
    "    datasets['taskA_reldim']['X'] = X\n",
    "    datasets['taskA_reldim']['y'] = targets \n",
    "\n",
    "    \n",
    "    # train task B reldim (motion):\n",
    "    datasets['taskB_reldim'] = {}\n",
    "    X = features[labels[:,0]==2]\n",
    "    targets = labels[labels[:,0]==2,1]    \n",
    "    targets = targets>3 # low vs high val for motion       \n",
    "    \n",
    "    datasets['taskB_reldim']['X'] = X\n",
    "    datasets['taskB_reldim']['y'] = targets \n",
    "\n",
    "\n",
    "    # train task A irreldim (motion):\n",
    "    datasets['taskA_irreldim'] = {}    \n",
    "    X = features[labels[:,0]==1]\n",
    "    targets = labels[labels[:,0]==1,1]    \n",
    "    targets = targets>3 # low vs high val for motion\n",
    "    \n",
    "    datasets['taskA_irreldim']['X'] = X\n",
    "    datasets['taskA_irreldim']['y'] = targets \n",
    "    \n",
    "    # train task B irreldim (colour):\n",
    "    datasets['taskB_irreldim'] = {}\n",
    "    X = features[labels[:,0]==2]\n",
    "    targets = labels[labels[:,0]==2,2]    \n",
    "    targets = targets>3 # low vs high colour        \n",
    "    \n",
    "    datasets['taskB_irreldim']['X'] = X\n",
    "    datasets['taskB_irreldim']['y'] = targets     \n",
    "\n",
    "\n",
    "    # # task A vs task B\n",
    "    # datasets['AvsB'] = {}\n",
    "    # datasets['AvsB']['X'] = features\n",
    "    # datasets['AvsB']['y'] = labels[:,0]\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def gen_traintestdata_runs(swapds=False):\n",
    "    \"\"\"loads and partitions the data into sets for training \n",
    "       and test. labels are given for the relevant and irrelevant \n",
    "       feature dimension of each task.\n",
    "\n",
    "    Args:\n",
    "        swapds (bool): whether or not to swap training and test set (for cross-val)\n",
    "    \"\"\"\n",
    "    data = loadmat(datadir+fn)\n",
    "    \n",
    "    if swapds:\n",
    "        datasets_train = partition_datasets(data['X_test'],data['y_test'])\n",
    "        datasets_test = partition_datasets(data['X_train'],data['y_train'])\n",
    "    else:\n",
    "        datasets_train = partition_datasets(data['X_train'],data['y_train'])\n",
    "        datasets_test = partition_datasets(data['X_test'],data['y_test'])\n",
    "\n",
    "    return datasets_train, datasets_test\n",
    "\n",
    "    \n",
    "def test_shuffle(X,y,clf):\n",
    "    y_shuff = y[np.random.permutation(len(y))]\n",
    "    yt = clf.predict(X)\n",
    "    return np.mean(y_shuff == yt)\n",
    "\n",
    "def fit_linear_svm(featuredim, C=1.0,do_pca=False):\n",
    "    \"\"\"trains and evaluates svm on fmri roi patterns \n",
    "       with split half cross-validation on 2880 pseudotrials (40 per condition)\n",
    "\n",
    "    Args:\n",
    "        \n",
    "        featuredim (str): dictionary key for feature to fit (for example taskA_reldim)\n",
    "        C (float): inverse regularisation strength (c in (0,1))\n",
    "        do_pca (bool): perform pca and retain data containing 95% of variance (yes/no)\n",
    "\n",
    "    Returns:\n",
    "        results: dictionary with training and test accuracies\n",
    "    \"\"\"\n",
    "    shuffle_accs = []\n",
    "    test_accs = []\n",
    "    train_accs = []\n",
    "    for run_id,doswap in enumerate([False,True]):\n",
    "        testaccs = []\n",
    "        shuffleaccs = []\n",
    "        datasets_train, datasets_test = gen_traintestdata_runs(swapds=doswap)\n",
    "        # training\n",
    "        sc = StandardScaler()\n",
    "        clf = SVC(C=C,kernel='linear')\n",
    "        X = datasets_train[featuredim]['X']\n",
    "        if do_pca:\n",
    "            pca = PCA(n_components=0.95,svd_solver='full')\n",
    "            X = pca.fit_transform(X)\n",
    "        \n",
    "        X = sc.fit_transform(X)\n",
    "        y = datasets_train[featuredim]['y']\n",
    "        clf.fit(X, y)\n",
    "        yt = clf.predict(X)\n",
    "        train_accs.append(np.mean(yt == y))\n",
    "\n",
    "        # test on all four test sets (A rel, B rel, A irrel, B irrel)\n",
    "        for _, testset in datasets_test.items():\n",
    "            X = testset['X']\n",
    "            if do_pca:\n",
    "                X = pca.transform(X)\n",
    "            X = sc.transform(X)\n",
    "            y = testset['y']\n",
    "            yt = clf.predict(X)\n",
    "            testaccs.append(np.mean(y == yt))\n",
    "            # compute shuffle distribution\n",
    "            sfs = Parallel(n_jobs=6,backend='loky',verbose=0)(delayed(test_shuffle)(X,y,clf) for _ in range(500))            \n",
    "            shuffleaccs.append(sfs)\n",
    "        shuffle_accs.append(shuffleaccs)    \n",
    "        test_accs.append(testaccs)\n",
    "    train_accs = np.asarray(train_accs)\n",
    "    test_accs = np.asarray(test_accs)\n",
    "    shuffle_accs = np.asarray(shuffle_accs)\n",
    "    \n",
    "    \n",
    "    # average over cross-val folds:\n",
    "    results = {'train_accs': np.mean(train_accs),\n",
    "               'test_accs': np.mean(test_accs, 0),\n",
    "               'shuff_accs':np.mean(shuffle_accs,0)\n",
    "               }\n",
    "\n",
    "    return results\n",
    "\n",
    "    \n",
    "def nonparam_test(t,t_shuff):\n",
    "    # return proportion of shuffled ts that exceed empirical t\n",
    "    # as approximation of p value\n",
    "    return np.mean(t_shuff>t)\n",
    "\n",
    "\n",
    "def plot_avg_svm_results(results,shuffresults):\n",
    "    # loop over training dimensions\n",
    "    mm = 1/25.4\n",
    "    f,axs = plt.subplots(1,1,figsize=(55*mm,40*mm),dpi=300)\n",
    "    \n",
    "   \n",
    "    dtes = ['same task rel','same task irrel', 'other task rel', 'other task irrel']\n",
    "    idces = [(0,0),(1,1)],[(0,2),(1,3)],[(0,1),(1,0)],[(0,3),(1,2)]\n",
    "    for k,idx in enumerate(idces):\n",
    "        avg_res = (results[idx[0][0],idx[0][1]]+results[idx[1][0],idx[1][1]])/2\n",
    "        avg_shuff = (shuffresults[idx[0][0],idx[0][1],:]+shuffresults[idx[1][0],idx[1][1],:])/2\n",
    "    \n",
    "        axs.bar(k,avg_res-avg_shuff.mean(),color=(0.5,0.7,0.6),edgecolor='k')\n",
    "    \n",
    "        axs.scatter(np.repeat(k,len(avg_shuff))+np.random.randn(len(avg_shuff))*0.01,avg_shuff-avg_shuff.mean(),color=(.9,.9,.9),alpha=0.4,zorder=3,s=10,edgecolor='k',linewidth=0.2)\n",
    "        axs.errorbar(k,0,yerr=2*np.std(avg_shuff),color='k',zorder=4)\n",
    "        axs.plot([-1,4],[0,0],'k--',linewidth=0.5)\n",
    "        p = nonparam_test(avg_res,avg_shuff)\n",
    "        print(f'tested on {dtes[k]}, \\t p= {p}, \\t mu={avg_res-avg_shuff.mean():.4f}')\n",
    "        \n",
    "        if p<0.05:\n",
    "            \n",
    "            if p <0.0001:\n",
    "                ts = '*'*4\n",
    "            elif p <0.001:\n",
    "                ts = '*'*3\n",
    "            elif p<0.01:\n",
    "                ts = '*'*2\n",
    "            elif p<0.05:\n",
    "                ts = '*'\n",
    "            axs.text(k,0.1,ts,{'fontsize':6,'ha':'center','fontweight':'normal'})\n",
    "\n",
    "\n",
    "    axs.set_xlabel('test dimension',fontsize=6)\n",
    "    axs.set_ylabel('test acc - chance (%)',fontsize=6)\n",
    "    axs.set_title('Monkey A',fontsize=6)\n",
    "    axs.set_yticks(np.arange(-0.2,0.21,0.1))\n",
    "    axs.set_ylim=(-0.1,0.2)\n",
    "    axs.set_xticks(np.arange(4))\n",
    "    axs.set_xticklabels(dtes,rotation=90,fontsize=6)\n",
    "    ticks = axs.get_yticks()\n",
    "    axs.set_yticklabels(np.round(ticks*100,2),fontsize=6)\n",
    "    axs.spines['top'].set_visible(False)\n",
    "    axs.spines['right'].set_visible(False)\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C=1.0\n",
    "dims = ['taskA_reldim', 'taskB_reldim','taskA_irreldim','taskB_irreldim']\n",
    "all_train_accs = np.empty((len(dims),1))\n",
    "all_test_accs = np.empty((len(dims), 4))\n",
    "all_shuffle_accs = np.empty((len(dims), 4, 500))\n",
    "\n",
    "for k, d in enumerate(dims):\n",
    "    print(f'processing {d} ...')\n",
    "    results = fit_linear_svm(C=C,do_pca=True,featuredim=d) \n",
    "    all_train_accs[k, :] = results['train_accs']\n",
    "    all_test_accs[k, :] = results['test_accs']\n",
    "    all_shuffle_accs[k, :, :] = results['shuff_accs']\n",
    "\n",
    "results = {'train_accs': all_train_accs,\n",
    "           'test_accs': all_test_accs,\n",
    "           'shuffle_accs':all_shuffle_accs,\n",
    "           'dims': dims,           \n",
    "           'regulariser': C\n",
    "           }\n",
    "\n",
    "with open('results_nhp_svm_pca.pkl', 'wb') as f:\n",
    "    pickle.dump(results,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.000e+00, 1.300e+01, 1.590e+02, 6.960e+02, 1.825e+03, 2.749e+03,\n",
       "        1.749e+03, 6.840e+02, 1.150e+02, 8.000e+00]),\n",
       " array([0.44166667, 0.45236111, 0.46305556, 0.47375   , 0.48444444,\n",
       "        0.49513889, 0.50583333, 0.51652778, 0.52722222, 0.53791667,\n",
       "        0.54861111]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQWElEQVR4nO3df6zddX3H8edLELcJhiJdh6Vb0dQ/6qLIbiqLbmEh42cyIC4MXLQQl5oImSaYWd0fMAgJGsXMyEjqrOKiEuaP2EkjVqIhLkO5ECwUxrhCGe0qvVqiMqMOfO+P8607q/f2/jjnnnPbz/ORnJzveX8/33M+b0pf99vv93u+N1WFJKkNLxr3BCRJo2PoS1JDDH1JaoihL0kNMfQlqSHHjnsCh3PyySfX2rVrxz0NSTqi3H///T+oqpUzrVvWob927VomJyfHPQ1JOqIkeWq2dR7ekaSGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhizrb+RKy9nazXeO5XN333ThWD5XRwf39CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ+YM/SRrknwjySNJdiV5V1e/LsneJA92jwv6tnlfkqkkjyU5t69+XlebSrJ5aVqSJM1mPvfTfx64pqoeSHICcH+SHd26j1TVh/oHJ1kPXAa8BngF8PUkr+5W3wL8KbAHuC/Jtqp6ZBiNSJLmNmfoV9U+YF+3/JMkjwKrD7PJRcDtVfVz4MkkU8CGbt1UVT0BkOT2bqyhL0kjsqBj+knWAq8Hvt2Vrk6yM8nWJCu62mrg6b7N9nS12eqHfsamJJNJJqenpxcyPUnSHOYd+kmOB74AvLuqfgzcCrwKOJ3evwQ+PIwJVdWWqpqoqomVK1cO4y0lSZ15/Y7cJC+mF/ifqaovAlTVM33rPw58pXu5F1jTt/mpXY3D1CVJIzCfq3cCfAJ4tKpu7quf0jfsEuDhbnkbcFmSlyQ5DVgHfAe4D1iX5LQkx9E72bttOG1IkuZjPnv6bwTeCjyU5MGu9n7g8iSnAwXsBt4BUFW7ktxB7wTt88BVVfUCQJKrgbuAY4CtVbVraJ1IkuY0n6t3vgVkhlXbD7PNjcCNM9S3H247SdLS8hu5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNmTP0k6xJ8o0kjyTZleRdXf2kJDuSPN49r+jqSfLRJFNJdiY5o++9NnbjH0+ycenakiTNZD57+s8D11TVeuBM4Kok64HNwN1VtQ64u3sNcD6wrntsAm6F3g8J4FrgDcAG4NqDPygkSaMxZ+hX1b6qeqBb/gnwKLAauAi4rRt2G3Bxt3wR8OnquRc4MckpwLnAjqo6UFXPAjuA84bZjCTp8BZ0TD/JWuD1wLeBVVW1r1v1fWBVt7waeLpvsz1dbbb6oZ+xKclkksnp6emFTE+SNId5h36S44EvAO+uqh/3r6uqAmoYE6qqLVU1UVUTK1euHMZbSpI68wr9JC+mF/ifqaovduVnusM2dM/7u/peYE3f5qd2tdnqkqQRmc/VOwE+ATxaVTf3rdoGHLwCZyPw5b7627qreM4EftQdBroLOCfJiu4E7jldTZI0IsfOY8wbgbcCDyV5sKu9H7gJuCPJ24GngEu7dduBC4Ap4KfAlQBVdSDJDcB93bjrq+rAMJqQJM3PnKFfVd8CMsvqs2cYX8BVs7zXVmDrQiYoSRoev5ErSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JD5vPlLGnZWrv5znFPQTqiuKcvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQr96RjjDjvGJp900Xju2zNRzu6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQOUM/ydYk+5M83Fe7LsneJA92jwv61r0vyVSSx5Kc21c/r6tNJdk8/FYkSXOZz57+p4DzZqh/pKpO7x7bAZKsBy4DXtNt8w9JjklyDHALcD6wHri8GytJGqE5f3NWVd2TZO083+8i4Paq+jnwZJIpYEO3bqqqngBIcns39pGFT1mStFiDHNO/OsnO7vDPiq62Gni6b8yerjZb/dck2ZRkMsnk9PT0ANOTJB1qsaF/K/Aq4HRgH/DhYU2oqrZU1URVTaxcuXJYbytJYpG/GL2qnjm4nOTjwFe6l3uBNX1DT+1qHKYuSRqRRe3pJzml7+UlwMEre7YBlyV5SZLTgHXAd4D7gHVJTktyHL2TvdsWP21J0mLMuaef5HPAWcDJSfYA1wJnJTkdKGA38A6AqtqV5A56J2ifB66qqhe697kauAs4BthaVbuG3Ywk6fDmc/XO5TOUP3GY8TcCN85Q3w5sX9DsJElD5TdyJakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JA5Qz/J1iT7kzzcVzspyY4kj3fPK7p6knw0yVSSnUnO6NtmYzf+8SQbl6YdSdLhzGdP/1PAeYfUNgN3V9U64O7uNcD5wLrusQm4FXo/JIBrgTcAG4BrD/6gkCSNzpyhX1X3AAcOKV8E3NYt3wZc3Ff/dPXcC5yY5BTgXGBHVR2oqmeBHfz6DxJJ0hJb7DH9VVW1r1v+PrCqW14NPN03bk9Xm63+a5JsSjKZZHJ6enqR05MkzWTgE7lVVUANYS4H329LVU1U1cTKlSuH9baSJBYf+s90h23onvd39b3Amr5xp3a12eqSpBFabOhvAw5egbMR+HJf/W3dVTxnAj/qDgPdBZyTZEV3AvecriZJGqFj5xqQ5HPAWcDJSfbQuwrnJuCOJG8HngIu7YZvBy4ApoCfAlcCVNWBJDcA93Xjrq+qQ08OS5KW2JyhX1WXz7Lq7BnGFnDVLO+zFdi6oNlJkobKb+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ+b8zVnSfKzdfOe4pyBpHgx9SfM2rh/uu2+6cCyfezTy8I4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0JekhgwU+kl2J3koyYNJJrvaSUl2JHm8e17R1ZPko0mmkuxMcsYwGpAkzd8w9vT/pKpOr6qJ7vVm4O6qWgfc3b0GOB9Y1z02AbcO4bMlSQuwFId3LgJu65ZvAy7uq3+6eu4FTkxyyhJ8viRpFoOGfgFfS3J/kk1dbVVV7euWvw+s6pZXA0/3bbunq/0/STYlmUwyOT09PeD0JEn9Br218puqam+S3wZ2JPn3/pVVVUlqIW9YVVuALQATExML2laSdHgD7elX1d7ueT/wJWAD8MzBwzbd8/5u+F5gTd/mp3Y1SdKILDr0k7w0yQkHl4FzgIeBbcDGbthG4Mvd8jbgbd1VPGcCP+o7DCRJGoFBDu+sAr6U5OD7fLaqvprkPuCOJG8HngIu7cZvBy4ApoCfAlcO8NmSpEVYdOhX1RPA62ao/xA4e4Z6AVct9vMkSYPzG7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrIon8xupantZvvHPcUJC1j7ulLUkMMfUlqiId3JC174zxsufumC8f22UvBPX1JaoihL0kNMfQlqSGGviQ1xNCXpIaMPPSTnJfksSRTSTaP+vMlqWUjDf0kxwC3AOcD64HLk6wf5RwkqWWjvk5/AzBVVU8AJLkduAh4ZMTzWFLeCkE6eozr7/NSfT9g1KG/Gni67/Ue4A39A5JsAjZ1L59L8tg83/tk4AcDz3B5s8ejgz0eHZa0x3xgoM1/b7YVy+4buVW1Bdiy0O2STFbVxBJMadmwx6ODPR4djtQeR30idy+wpu/1qV1NkjQCow79+4B1SU5LchxwGbBtxHOQpGaN9PBOVT2f5GrgLuAYYGtV7RrS2y/4kNARyB6PDvZ4dDgie0xVjXsOkqQR8Ru5ktQQQ1+SGnJEhP58b92Q5M1JKsnEIfXfTfJckvcs/WwXbpD+krw2yb8l2ZXkoSS/MZpZL8xie0zy4iS3db09muR9o5v1wszVY5IrkkwnebB7/FXfuo1JHu8eG0c78/lbbI9JTu/7/3Rnkr8Y/eznZ5A/x279y5LsSfKx0c16AapqWT/onfD9HvBK4Djgu8D6GcadANwD3AtMHLLu88A/A+8Zdz/D7I/eifidwOu61y8Hjhl3T0Pu8S3A7d3ybwG7gbXj7mkxPQJXAB+bYduTgCe65xXd8opx9zTkHl8NrOuWXwHsA04cd0/D7LFv/d8Dnz3cmHE+joQ9/V/duqGqfgEcvHXDoW4APgD8rL+Y5GLgSWBYVwkN2yD9nQPsrKrvAlTVD6vqhaWe8CIM0mMBL01yLPCbwC+AHy/xfBdjvj3O5FxgR1UdqKpngR3AeUs0z0Esuseq+o+qerxb/i9gP7ByyWa6eIP8OZLkD4BVwNeWaH4DOxJCf6ZbN6zuH5DkDGBNVd15SP144L3A3y31JAew6P7o7T1VkruSPJDkb5Z2qos2SI+fB/6b3p7hfwIfqqoDSzjXxZqzx86bu8Mbn09y8IuK89123Abp8VeSbKC3F/29pZnmQBbdY5IXAR8GluVh5IOOhNA/rO4/9M3ANTOsvg74SFU9N9JJDdEc/R0LvAn4y+75kiRnj3B6QzFHjxuAF+gdEjgNuCbJK0c4vWH6F3qHpl5Lb2/+tjHPZykctsckpwD/BFxZVb8cw/yGYbYe3wlsr6o9Y5vZPCy7e+/MYK5bN5wA/D7wzSQAvwNsS/Jn9G7m9udJPgicCPwyyc+qajmdYBmkvz3APVX1A4Ak24EzgLtHMO+FGKTHtwBfrar/AfYn+Vdggt5x7+VkzluMVNUP+17+I/DBvm3POmTbbw59hoMbpEeSvAy4E/jbqrp3Cec5iEF6/EPgj5K8EzgeOC7Jc1W1vH5vyLhPKszjxMqx9P6Cn8b/nVh5zWHGf5NDTuR29etYnidyF90fvZN+D9A7wXks8HXgwnH3NOQe3wt8slt+Kb3bcL923D0tpkfglL7lS4B7u+WT6J13WtE9ngROGndPQ+7xOHo7I+8edx9L1eMhY65gmZ7IXfZ7+jXLrRuSXA9MVtURfe+eQfqrqmeT3EzvnkZF75+Wy+5m/gP+Gd4CfDLJLiD0fgDsXPpZL8w8e/zr7l8vzwMH6AUDVXUgyQ30/hwBrq9leN5ikB6BS4E/Bl6e5GDtiqp6cIQtzGnAHo8I3oZBkhpyxJ/IlSTNn6EvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGvK/doHohkTJlQgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(results['shuffle_accs'][:,:,:].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested on same task rel, \t p= 0.0, \t mu=0.0668\n",
      "tested on same task irrel, \t p= 0.996, \t mu=-0.0235\n",
      "tested on other task rel, \t p= 1.0, \t mu=-0.0318\n",
      "tested on other task irrel, \t p= 0.064, \t mu=0.0116\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('results_nhp_svm_pca.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "%matplotlib qt\n",
    "dims_train =  ['taskA_reldim', 'taskB_reldim']\n",
    "dims_test = ['taskA_reldim', 'taskB_reldim','taskA_irreldim', 'taskB_irreldim']\n",
    "plot_avg_svm_results(results['test_accs'],results['shuffle_accs'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b7b770bd4df7f5d53ce25a065472836ccdb5063edf5f6149aa55dabe0a07e90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pytorch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
